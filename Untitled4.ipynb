{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Отбор на позицию Intern-ML Вконтакте**\n",
        "## **Задание**: создать embeddings пользователей и фильмов по датасету отзывов на фильмы MovieLens, используя нейросетевые методы. Реализовать поиск рекомендаций (embeddings фильмов) по embedding пользователя."
      ],
      "metadata": {
        "id": "GHtbxPTqa4rR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UMXEZ_qSaWbB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "import scipy.stats\n",
        "import warnings\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "sns.set(style='whitegrid', font_scale=1.3, palette='Set2')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from gensim.models import Word2Vec\n",
        "from scipy.spatial.distance import cosine\n"
      ],
      "metadata": {
        "id": "BqS0ek6LadQX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Загрузка данных"
      ],
      "metadata": {
        "id": "aKtjN86Cb0ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cS69rOgqfZ5X",
        "outputId": "d342b416-cf21-4a4b-9245-0aa85e039787"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies = pd.read_csv(\"/content/drive/MyDrive/Vk отбор/movies.csv\")\n",
        "ratings = pd.read_csv(\"/content/drive/MyDrive/Vk отбор/ratings.csv\")\n",
        "tags = pd.read_csv(\"/content/drive/MyDrive/Vk отбор/tags.csv\")\n"
      ],
      "metadata": {
        "id": "FBY43NQWa2cj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(movies.head(5))\n",
        "print(ratings.head(5))\n",
        "print(tags.head(5))\n",
        "# print(links.head(5))\n",
        "# print(genome_tags.head(5))\n",
        "# print(genome_scores.head(5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pBEGaDrgPYG",
        "outputId": "09759fe1-baa1-4b9a-834b-6c9597ba4a6c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n",
            "   userId  movieId  rating   timestamp\n",
            "0       1      307     3.5  1256677221\n",
            "1       1      481     3.5  1256677456\n",
            "2       1     1091     1.5  1256677471\n",
            "3       1     1257     4.5  1256677460\n",
            "4       1     1449     4.5  1256677264\n",
            "   userId  movieId           tag   timestamp\n",
            "0      14      110          epic  1443148538\n",
            "1      14      110      Medieval  1443148532\n",
            "2      14      260        sci-fi  1442169410\n",
            "3      14      260  space action  1442169421\n",
            "4      14      318  imdb top 250  1442615195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline**: для начала создадим эмбеддинг для каждого фильма, чтобы на выходе получилась таблица, содержашая id фильма и n-мерный вектор. Для более качественного кодирования, посчитаем по каждому фильму среднюю оценку, используем его название и жанр. "
      ],
      "metadata": {
        "id": "WVDoUnYqpV2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_rate = ratings.groupby('movieId')['rating'].mean()\n",
        "movies_emb_prep = pd.merge(avg_rate, movies, on='movieId')"
      ],
      "metadata": {
        "id": "sonaejCmqkbv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставим только название фильма, без года выпуска. "
      ],
      "metadata": {
        "id": "UGxHcpuDvD0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer('basic_english')\n",
        "movies_emb = movies_emb_prep.copy()\n",
        "\n",
        "movies_emb['title'] = movies_emb['title'].str.lower().replace(r'[^a-zA-Z ]+', '', regex=True)\n",
        "movies_emb['genres'] = movies_emb['genres'].str.lower().str.replace('|', ' ')\n",
        "\n",
        "movies_emb[\"title\"] = movies_emb[\"title\"].apply(tokenizer)\n",
        "movies_emb[\"genres\"] = movies_emb[\"genres\"].apply(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXYj2gcEtOwX",
        "outputId": "d6916369-7285-41b8-c5be-52eb0f7d1a93"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-5ad222bb2554>:5: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  movies_emb['genres'] = movies_emb['genres'].str.lower().str.replace('|', ' ')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "model = Word2Vec(movies_emb['title'] + movies_emb['genres'], vector_size=embedding_dim, min_count=1)"
      ],
      "metadata": {
        "id": "tHmabenR1jPB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = np.zeros((len(movies_emb), 2*embedding_dim + 1))\n",
        "\n",
        "for i in range(len(movies_emb)):\n",
        "    title_embedding = np.mean([model.wv[word] for word in movies_emb.iloc[i]['title']], axis=0)\n",
        "    genre_embedding = np.mean([model.wv[word] for word in movies_emb.iloc[i]['genres']], axis=0)\n",
        "    rating_embedding = movies_emb.iloc[i]['rating']\n",
        "    \n",
        "    if ((genre_embedding.shape == (100,)) and (title_embedding.shape == (100,))):    \n",
        "      embeddings[i] = np.concatenate((title_embedding, genre_embedding, [rating_embedding]))\n",
        "\n"
      ],
      "metadata": {
        "id": "eJzZL4lO1_iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74f7c6c-c1f2-4631-9c72-3337564bf11f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим, качественно ли у нас произошел эмбеддинг: посчитаем расстояние между векторами, используя scipy.distance"
      ],
      "metadata": {
        "id": "lA9bA04gKk22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sorted = movies_emb.sort_values(by='genres')\n",
        "\n",
        "print(cosine(embeddings[6809], embeddings[3716]), \"Одна категория\")\n",
        "print(cosine(embeddings[34019], embeddings[34021]),  \"Одна категория\")\n",
        "print(cosine(embeddings[6809], embeddings[34021]), \"Разные категории\")"
      ],
      "metadata": {
        "id": "EQcdiYPXFUaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a75a59c0-a74a-4222-d394-784b4d916b34"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03536157523417294 Одна категория\n",
            "0.019765689489869676 Одна категория\n",
            "0.36170427886011336 Разные категории\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ура, все хорошо, все работает"
      ],
      "metadata": {
        "id": "AWz4ho7GSFh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movies_emb['film_inf'] = embeddings.tolist()\n",
        "movies_emb.drop(columns=['rating', 'title', 'genres'], inplace=True)"
      ],
      "metadata": {
        "id": "prDySc5mSOrf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Совместим датафрейм рейтингов зрителей с тегами и векторным описанием фильмов, полученным на предыдущем шаге. "
      ],
      "metadata": {
        "id": "Tye_-qj3UGpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.merge(ratings, movies_emb, on='movieId')\n",
        "data = pd.merge(data, tags, on=['userId', 'movieId'], how='left')\n",
        "data = data.fillna(\"\")\n",
        "data.drop(columns='timestamp_y', inplace=True)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "Ypv7OzkoSzpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c7b761-1eee-415b-ece0-f6ba137212fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          userId  movieId  rating  timestamp_x  \\\n",
            "0              1      307     3.5   1256677221   \n",
            "1              6      307     4.0    832059248   \n",
            "2             56      307     4.0   1383625728   \n",
            "3             71      307     5.0   1257795414   \n",
            "4             84      307     3.0    999055519   \n",
            "...          ...      ...     ...          ...   \n",
            "28363491  282403   167894     1.0   1524243885   \n",
            "28363492  282732   161572     3.5   1504408070   \n",
            "28363493  283000   117857     3.5   1417317969   \n",
            "28363494  283000   133409     3.5   1431539331   \n",
            "28363495  283000   142855     3.5   1442889934   \n",
            "\n",
            "                                                   film_inf          tag  \n",
            "0         [-0.04183252528309822, 0.09439527243375778, 0....               \n",
            "1         [-0.04183252528309822, 0.09439527243375778, 0....               \n",
            "2         [-0.04183252528309822, 0.09439527243375778, 0....               \n",
            "3         [-0.04183252528309822, 0.09439527243375778, 0....               \n",
            "4         [-0.04183252528309822, 0.09439527243375778, 0....               \n",
            "...                                                     ...          ...  \n",
            "28363491  [-0.004857304040342569, -0.003414778970181942,...               \n",
            "28363492  [-0.10991386324167252, 0.27771642804145813, 0....               \n",
            "28363493  [-0.01550690084695816, 0.006023992784321308, 0...  documentary  \n",
            "28363494  [4.317640559747815e-06, 0.0055892691016197205,...               \n",
            "28363495  [-0.018678471446037292, 0.03165020793676376, 0...               \n",
            "\n",
            "[28363496 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим эмбедденги для пользователей, основываясь на полученных векторах фильмов."
      ],
      "metadata": {
        "id": "0WeBM9B2WamA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# создание эмбеддингов пользователей\n",
        "grouped_data = data.groupby('userId')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "user_embeddings = {}\n",
        "for user_id, group in tqdm(grouped_data):\n",
        "    movie_embeddings = np.array(list(group['film_inf']))\n",
        "    weights = np.array(list(group['rating'])) # использование оценок как весов\n",
        "    user_embeddings[user_id] = np.average(movie_embeddings, axis=0, weights=weights)\n"
      ],
      "metadata": {
        "id": "Kz0gYvYvb-o-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d214bdaf-29c4-470b-811c-efe381381383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 100869/283228 [04:33<11:36, 261.73it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полученные данные позволяют качественно обучить по ним нейронную сеть. Для этого можно использовать различные методы и библиотеки: машины факторизации, колоборативную фильтрацию, BERT-технологию и т.д. Ниже я привожу реализацию одного из вариантов с использованием метрики MAE. К сожалению, в силу отсутствия вычислительных способностей для большого варианта датасета MovieLens протестировать этот код я не успеваю к дедлайну. Я благодарю за возможность изучить новые для себя NLP-технологии и надеюсь на дальнейшее сотрудничество!"
      ],
      "metadata": {
        "id": "gbBAvB2PbICL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбивка на тренировочный и тестовый наборы данных\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# создание матрицы признаков\n",
        "X_train = np.array(train_data['film_inf'].values.tolist())\n",
        "y_train = train_data['rating'].values\n",
        "\n",
        "# определение архитектуры нейронной сети\n",
        "input_layer = Input(shape=(100,))\n",
        "hidden_layer = Dense(64, activation='relu')(input_layer)\n",
        "output_layer = Dense(1)(hidden_layer)\n",
        "\n",
        "# компиляция модели\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
        "\n",
        "# обучение модели на тренировочном наборе данных\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# предсказание оценок на тестовом наборе данных\n",
        "X_test = np.array(test_data['film_inf'].values.tolist())\n",
        "y_test = test_data['rating'].values\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# вычисление MAE\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE:', mae)"
      ],
      "metadata": {
        "id": "Xqyl9AfwZgdz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}